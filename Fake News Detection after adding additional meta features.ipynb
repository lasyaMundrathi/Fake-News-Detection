{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fJht4bHsNs8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b6ab3c-44fb-47a3-d16a-f024fea53ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import csv   # csv reader\n",
        "import re    # regular expressions\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
        "from random import shuffle\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.pipeline import Pipeline\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "# Vader consists of list of words which are annotated as positive,neagative,neutraland compound\n",
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"Id\":  # skip header\n",
        "                continue\n",
        "            \"\"\"parse data line function returns labels and all the meta features\"\"\"\n",
        "            label, text,subject,speaker,speaker_job_title,state_info,party_affiliation,total_barely_true_counts, total_false_counts,total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context,negative,neutral,positive,compound = parse_data_line(line)\n",
        "            raw_data.append(((text,subject,speaker,speaker_job_title,state_info,party_affiliation,total_barely_true_counts, total_false_counts,total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context,negative,neutral,positive,compound),label))\n",
        "\n",
        "def split_and_preprocess_data(percentage):\n",
        "    \"\"\"\n",
        "    splits raw data into training and testing based on the percentage parameter. \n",
        "    Train data consists of 40% data from the first half of raw data and 40% data from the second half of the raw data\n",
        "    test data consists of 10% data from the first half and 10% data from the second half of the raw data.\n",
        "    For suppose let us consider the total samples are 100 and the percentage parameter is 0.8. then half of the data is 50,\n",
        "     samples are 0.8*100/2 which is 40. Using these variables, we divide the raw data into  \n",
        "    train data=raw data [0:40] +raw data [50:90].  \n",
        "    Test data=raw data [ 40:50]+raw data [90:100] \n",
        "    \"\"\"\n",
        "    num_samples = len(raw_data)\n",
        "    half_samples=int(len(raw_data)/2)\n",
        "    training_samples=int((percentage*num_samples)/2) \n",
        "    train_data.extend(raw_data[:training_samples] + raw_data[half_samples:half_samples+training_samples])\n",
        "    test_data.extend(raw_data[training_samples:half_samples] + raw_data[half_samples+training_samples:])"
      ],
      "metadata": {
        "id": "BK0QQHBqOff2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Id', 'label', 'statement', 'subject', 'speaker', 'speaker_job_title', 'state_info', 'party_affiliation', 'total_barely_true_counts', 'total_false_counts total_half_true_counts', 'total_mostly_true_counts', 'total_pants_on_fire_counts', 'context']"
      ],
      "metadata": {
        "id": "TSJgMAeR1DYd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas._config.config import ContextDecorator\n",
        "def convert_label(label):\n",
        "      \"\"\"\n",
        "      Converts the multiple classes into two,\n",
        "      making it a binary distinction between fake news and real.\n",
        "      \"\"\"\n",
        "      #return label\n",
        "      # Converting the multiclass labels to binary label\n",
        "      labels_map = {\n",
        "          'true': 'REAL',\n",
        "          'mostly-true': 'REAL',\n",
        "          'half-true': 'REAL',\n",
        "          'false': 'FAKE',\n",
        "          'barely-true': 'FAKE',\n",
        "          'pants-fire': 'FAKE'\n",
        "      }\n",
        "      return labels_map[label]\n",
        "\n",
        "def parse_data_line(data_line):\n",
        "    \"\"\"\n",
        "    From the tab separated dataline extracting all the additional features from the fake news data\n",
        "    It uses \"convert_labels\" function to convert labels into fake or real\n",
        "    sid assigns a polarity of scores for each statement score includes positive,negative,neutral,compound\n",
        "    returns labels,statement,subject,speaker,speaker_job and other features along with the polarities \n",
        "    in the form of string for our convenience\n",
        "    \"\"\"\n",
        "    label=convert_label(data_line[1])\n",
        "    statement=data_line[2]\n",
        "    subject = data_line[3]\n",
        "    speaker = data_line[4]\n",
        "    speaker_job_title = data_line[5]\n",
        "    state_info = data_line[6]\n",
        "    party_affiliation = data_line[7]\n",
        "    context = data_line[13]\n",
        "    total_barely_true_counts = data_line[8]\n",
        "    total_false_counts = data_line[9]\n",
        "    total_half_true_counts = data_line[10]\n",
        "    total_mostly_true_counts = data_line[11]\n",
        "    total_pants_on_fire_counts = data_line[12]\n",
        "    ss = sid.polarity_scores(statement)\n",
        "    return label.strip().lower(),statement,subject,speaker,speaker_job_title,state_info,party_affiliation,total_barely_true_counts, total_false_counts,total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts,context,str(ss['neg']),str(ss['neu']),str(ss['pos']),str(ss['compound'])\n",
        "            "
      ],
      "metadata": {
        "id": "DVt5UtL5O3U0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGAzzJubRI_i",
        "outputId": "29909c65-4a63-4ad7-acbf-b1715f1a9a33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer     # lemmatization\n",
        "# TEXT PREPROCESSING AND FEATURE VECTORIZATION\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# TEXT PREPROCESSING AND FEATURE VECTORIZATION\n",
        "ps = PorterStemmer()\n",
        "# input: a string of one review\n",
        "def pre_process(text):\n",
        "    # word tokenisation, including punctuation removal\n",
        "    text = re.sub('[^A-Za-z0-9]+', ' ', text)\n",
        "    \"\"\"\n",
        "    preprocess the additional features called from the \"pre process_all_features\" function .\n",
        "    word tokenizer returns  \n",
        "    lowercasing and returns list of tokens and lemmatized words \n",
        "    \"\"\"\n",
        "    tokens = word_tokenize(text)\n",
        "    # # lowercasing\n",
        "    words = [token.lower() for token in tokens]\n",
        "    words1=[]\n",
        "    for word in words:\n",
        "        words1.append(re.sub('[^a-zA-z0-9]','',word))\n",
        "    token_words = [snowball_stemmer.stem(word) for word in words1]\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in words1]\n",
        "    return list(set(token_words + lemmatized_words))\n",
        "\n",
        "print(pre_process(\"hello ! how can I help you 1 ?\"))"
      ],
      "metadata": {
        "id": "8rwzDHWzPJgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67bb81f-3a81-4be2-d89b-7ac20b8dc8a1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'you', 'can', 'how', 'help', '1', 'i']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')\n",
        "# Vader consists of list of words which are annotated as positive,neagative,neutraland compound\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zJJrHfQXAyS",
        "outputId": "9cda058e-40f6-4f45-930e-daa2c7f82e4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_all_features(x):\n",
        "  \"\"\"\n",
        "  preprocessing some of the additional features using preprocess function\n",
        "  converting all the numerical values to string for consistency\n",
        "  token_output consists of string of polarity scores of text and list of\n",
        "  numerical features with extracted tokens from the preprocessed data\n",
        "  \"\"\"\n",
        "  text,subject,speaker,speaker_job_title,state_info,party_affiliation,total_barely_true_counts, total_false_counts,total_half_true_counts, total_mostly_true_counts, total_pants_on_fire_counts, context,negative,neutral,positive,compound = x\n",
        "  text_tokens  = pre_process(text)\n",
        "  speaker_tokens  = pre_process(speaker)\n",
        "  job_title_tokens  = pre_process(speaker_job_title)\n",
        "  salary_tokens  = pre_process(state_info)\n",
        "  party_tokens  = pre_process(party_affiliation)\n",
        "  context_tokens = pre_process(context)\n",
        "  tokens_output = [str(float(negative)+float(neutral)+float(positive)+float(compound))]+ [total_barely_true_counts + total_false_counts+total_half_true_counts+total_mostly_true_counts + total_pants_on_fire_counts]+text_tokens + speaker_tokens +job_title_tokens+salary_tokens+ party_tokens +context_tokens                                                                                                               \n",
        "  return tokens_output"
      ],
      "metadata": {
        "id": "8AuuPJvu62bF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9RD0Wo95Ceov"
      },
      "outputs": [],
      "source": [
        "def splitFeaturesAndLabels(data_set):\n",
        "   #extracting features and labels from the data \n",
        "    features, labels = zip(*data_set) \n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "def train_classifier(trainData):\n",
        "    features, labels = splitFeaturesAndLabels(trainData)\n",
        "    \"\"\" \n",
        "    Pipeline does feature extraction and uses machine learning model for classifying labels\n",
        "    Tfidf-tokens are returned form the \"preprocess_all_features\" function where stemming,lemmatization, lowercasing and other pre processing \n",
        "    converts the tokens into unigram, bigrams and tri grams and does for assigning weights for the feature i'm opting tfidf method\n",
        "    opting smooth_idf method for smoothing unknown tokens which appear only in test data\n",
        "    \"\"\"\n",
        "    pipeline = Pipeline([('tfidf', TfidfVectorizer(tokenizer = preprocess_all_features, ngram_range = (1, 3), lowercase=False, smooth_idf=True, use_idf=True)), \n",
        "                         ('svc', LinearSVC(class_weight = 'balanced'))])\n",
        "    pipeline.fit(features, labels)\n",
        "    return pipeline\n"
      ],
      "metadata": {
        "id": "w2-xKOQeV0L1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_labels(samples, classifier):\n",
        "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
        "    return classifier.predict(samples)\n",
        "\n",
        "def predict_label_from_raw(sample, classifier):\n",
        "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
        "    return classifier.classify(to_feature_vector(preProcess(sample)))"
      ],
      "metadata": {
        "id": "Tkb7z4s0WC5R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import shuffle\n",
        "\n",
        "def cross_validate(dataset, folds):\n",
        "    shuffle(dataset)\n",
        "    cv_scores = []\n",
        "    fold_size = int(len(dataset)/folds) + 1\n",
        "\n",
        "    for i in range(0,len(dataset),int(fold_size)):\n",
        "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
        "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
        "\n",
        "        data_train = dataset[ i + fold_size:] +  dataset[0: i] \n",
        "        data_val = dataset[i:i+fold_size]      \n",
        "        #splitting data into features and labels\n",
        "        val_feat, val_labels = splitFeaturesAndLabels(data_val)\n",
        "  \n",
        "        classifier = train_classifier(data_train)\n",
        "        val_label = [x[1] for x in data_val]\n",
        "        val_data1 = [x[0] for x in data_val]\n",
        "        # print(val_data[0:2])\n",
        "\n",
        "        val_pred = predict_labels(val_data1, classifier)\n",
        "    \n",
        "        #precision, recall, fscore, _ = metrics.precision_recall_fscore_support(validation_labels, predicted_labels, average='weighted')\n",
        "        cv_scores.append(precision_recall_fscore_support(val_label, val_pred, average='weighted'))\n",
        "        accuracy = metrics.accuracy_score(val_label, val_pred)\n",
        "    avgResults = [np.mean([x[0] for x in cv_scores]),\n",
        "                   np.mean([x[1] for x in cv_scores]),\n",
        "                   np.mean([x[2] for x in cv_scores]),\n",
        "                ]           \n",
        "    \"\"\"\n",
        "    STEPS:\n",
        "        1.for the cross validation, data set is divided into 10 folds, for each fold a training and validation data is created. \n",
        "        2. Here i is increment by fold size in each iteration untill length of the dataset. \n",
        "           suppose i =1 and fold size is 100 validation data is collected from data having index [1 + (1+foldsize):] and training data is collected \n",
        "            from index [0:1]+[1+foldsize:]. \n",
        "        3.Linear SVM classifier trains on the training data.\n",
        "        4.labels and data is collected from the validation data for further prediction.\n",
        "        5.precision, recall, fscore and support is calculated using validation labels and labels predicted from the classifier.\n",
        "        6.accuracy is found using the metrics. \n",
        "        7. for each iteration from the step 2 all the steps are repeated.\n",
        "        8. average results are calculated for each metrics and returned in the form of lists \n",
        "    \"\"\"\n",
        "        \n",
        "    return avgResults"
      ],
      "metadata": {
        "id": "DSAPd24kW-Zy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "raw_data = []          # the filtered data from the dataset file\n",
        "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
        "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
        "\n",
        "\n",
        "# references to the data files\n",
        "data_file_path = 'fake_news.tsv'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "\n",
        "load_data(data_file_path) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "\n",
        "split_and_preprocess_data(0.8)\n",
        "\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Training Samples: \", len(train_data), sep='\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6yeYiIAXC9x",
        "outputId": "b63ba6c4-2ac3-432a-8a4d-ea7979276a5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 10241 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
            "Training Samples: \n",
            "8192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results = cross_validate(train_data, 10)\n",
        "print('Precision_score: {0}\\n Recall_score: {1}\\n FScore: {2}\\n'.format(cv_results[0], cv_results[1], cv_results[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCVAW2OPXDd3",
        "outputId": "ac5a3b95-1345-4142-fe28-13b3fff5e06c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 0 - 820\n",
            "Fold start on items 820 - 1640\n",
            "Fold start on items 1640 - 2460\n",
            "Fold start on items 2460 - 3280\n",
            "Fold start on items 3280 - 4100\n",
            "Fold start on items 4100 - 4920\n",
            "Fold start on items 4920 - 5740\n",
            "Fold start on items 5740 - 6560\n",
            "Fold start on items 6560 - 7380\n",
            "Fold start on items 7380 - 8200\n",
            "Precision_score: 0.6966156664194634\n",
            " Recall_score: 0.6972545956986662\n",
            " FScore: 0.6952406722914374\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, check the accuracy of your classifier by training on all the traning data\n",
        "# and testing on the test set\n",
        "# Will only work once all functions are complete\n",
        "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
        "if functions_complete:\n",
        "    print(test_data[0])   # have a look at the first test data instance\n",
        "    classifier = train_classifier(train_data)  # train the classifier\n",
        "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
        "    test_pred = predict_labels([x[0] for x in test_data], classifier)  #Â classify the test data to get predicted labels\n",
        "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
        "    print(\"Done training!\")\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
      ],
      "metadata": {
        "id": "SkMCw9RHVo_Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6059b4b5-f336-414f-c395-e8d7a8430e9d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('I fought to bring about the largest private-sector infrastructure project in North American history.', 'energy', 'sarah-palin', '', 'Alaska', 'republican', '9', '19', '9', '6', '6', 'a radio address', '0.161', '0.839', '0.0', '-0.3182'), 'real')\n",
            "Done training!\n",
            "Precision: 0.693671\n",
            "Recall: 0.694973\n",
            "F Score:0.691586\n"
          ]
        }
      ]
    }
  ]
}